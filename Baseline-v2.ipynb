{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to your train/test/meta folders\n",
    "DATA_PATH = './data/'\n",
    "\n",
    "# names of valuable files/folders\n",
    "train_meta_fname = 'train.csv'\n",
    "test_meta_fname = 'sample_submission.csv'\n",
    "train_data_folder = 'audio_train/train/'\n",
    "test_data_folder = 'audio_test/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from torchaudio import transforms\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seeds\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bcbcc394ba64fe85ed4.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00d77b917e241afa06f1.wav</td>\n",
       "      <td>Squeak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fname            label\n",
       "0  8bcbcc394ba64fe85ed4.wav  Finger_snapping\n",
       "1  00d77b917e241afa06f1.wav           Squeak"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(os.path.join(DATA_PATH, train_meta_fname))\n",
    "df_test = pd.read_csv(os.path.join(DATA_PATH, test_meta_fname))\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8bcbcc394ba64fe85ed4.wav</td>\n",
       "      <td>Finger_snapping</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00d77b917e241afa06f1.wav</td>\n",
       "      <td>Squeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17bb93b73b8e79234cb3.wav</td>\n",
       "      <td>Electric_piano</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7d5c7a40a936136da55e.wav</td>\n",
       "      <td>Harmonica</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17e0ee7565a33d6c2326.wav</td>\n",
       "      <td>Snare_drum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      fname            label  label_encoded\n",
       "0  8bcbcc394ba64fe85ed4.wav  Finger_snapping              0\n",
       "1  00d77b917e241afa06f1.wav           Squeak              1\n",
       "2  17bb93b73b8e79234cb3.wav   Electric_piano              2\n",
       "3  7d5c7a40a936136da55e.wav        Harmonica              3\n",
       "4  17e0ee7565a33d6c2326.wav       Snare_drum              4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters\n",
    "fft_size = 2048\n",
    "overlap = 4\n",
    "hop = fft_size // overlap\n",
    "mels = 64\n",
    "\n",
    "\n",
    "n_classes = df_train.label.nunique()\n",
    "print(n_classes)\n",
    "classes_dict = {cl:i for i,cl in enumerate(df_train.label.unique())}\n",
    "df_train['label_encoded'] = df_train.label.map(classes_dict)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lukemelas/EfficientNet-PyTorch\n",
    "class BaseLineModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, sample_rate=16000, n_classes=41):\n",
    "        super().__init__()\n",
    "        self.ms = torchaudio.transforms.MelSpectrogram(sample_rate, n_mels = mels, n_fft=fft_size, hop_length=hop)\n",
    "#         self.bn1 = nn.BatchNorm2d(1)\n",
    "        \n",
    "        self.cnn1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3, padding=1)\n",
    "        self.cnn3 = nn.Conv2d(in_channels=10, out_channels=3, kernel_size=3, padding=1)\n",
    "        \n",
    "        self.features = EfficientNet.from_pretrained('efficientnet-b1')\n",
    "        # print(self.features)\n",
    "        # use it as features\n",
    "        # for param in self.features.parameters():\n",
    "        #     param.requires_grad = False\n",
    "            \n",
    "        self.lin1 = nn.Linear(1000, 333)\n",
    "        \n",
    "        self.lin2 = nn.Linear(333, 111)\n",
    "                \n",
    "        self.lin3 = nn.Linear(111, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.ms(x)\n",
    "#         x = self.bn1(x)\n",
    "                \n",
    "        x = F.relu(self.cnn1(x))\n",
    "        x = F.relu(self.cnn3(x))\n",
    "        \n",
    "        x = self.features(x)\n",
    "\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "    def inference(self, x):\n",
    "        x = self.forward(x)\n",
    "        x = F.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_or_pad(waveform, wav_len=32000):\n",
    "    m, n = waveform.shape\n",
    "    if n < wav_len:\n",
    "        padded_wav = torch.zeros(1, wav_len)\n",
    "        padded_wav[:, :n] = waveform\n",
    "        return padded_wav\n",
    "    elif n > wav_len:\n",
    "        offset = np.random.randint(0, n - wav_len)\n",
    "        sampled_wav = waveform[:, offset:offset+wav_len]\n",
    "        return sampled_wav\n",
    "    else:\n",
    "        return waveform\n",
    "        \n",
    "class EventDetectionDataset(Dataset):\n",
    "    def __init__(self, data_path, x, y=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.data_path = data_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path2wav = os.path.join(self.data_path, self.x[idx])\n",
    "        #waveform, sample_rate = torchaudio.load(path2wav, normalization=True)\n",
    "        waveform, sample_rate = torchaudio.load(path2wav)\n",
    "        waveform = sample_or_pad(waveform)\n",
    "        if self.y is not None:\n",
    "            return waveform, self.y[idx]\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train.fname.values, df_train.label_encoded.values, \n",
    "                                                  test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(\n",
    "                        EventDetectionDataset(os.path.join(DATA_PATH, train_data_folder), X_train, y_train),\n",
    "                        batch_size=41\n",
    "                )\n",
    "val_loader = DataLoader(\n",
    "                        EventDetectionDataset(os.path.join(DATA_PATH, train_data_folder), X_val, y_val),\n",
    "                        batch_size=41\n",
    "                )\n",
    "test_loader = DataLoader(\n",
    "                        EventDetectionDataset(os.path.join(DATA_PATH, test_data_folder), df_test.fname.values, None),\n",
    "                        batch_size=41, shuffle=False\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, eval_dataset):\n",
    "    model.eval()\n",
    "    forecast, true_labs = [], []\n",
    "    with torch.no_grad():\n",
    "        for wavs, labs in tqdm(eval_dataset):\n",
    "            #wavs, labs = wavs.cuda(), labs.detach().numpy()\n",
    "            labs = labs.detach().numpy()\n",
    "            true_labs.append(labs)\n",
    "            outputs = model.inference(wavs)\n",
    "            \n",
    "            outputs = outputs.detach().cpu().numpy().argmax(axis=1)\n",
    "            forecast.append(outputs)\n",
    "    forecast = [x for sublist in forecast for x in sublist]\n",
    "    true_labs = [x for sublist in true_labs for x in sublist]\n",
    "    return f1_score(forecast, true_labs, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "model = BaseLineModel()\n",
    "#model = model.cuda()\n",
    "lr = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [10:11<00:00,  5.51s/it]\n",
      "  0%|          | 0/28 [00:00<?, ?it/s]C:\\Users\\rethn\\anaconda3\\envs\\environmentkaggle\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 28/28 [01:45<00:00,  3.78s/it]\n",
      "100%|██████████| 111/111 [03:55<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, f1_test: 0.07767871742336283, f1_train: 0.08078379672255603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [08:04<00:00,  4.37s/it]\n",
      "100%|██████████| 28/28 [00:56<00:00,  2.03s/it]\n",
      "100%|██████████| 111/111 [04:22<00:00,  2.36s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, f1_test: 0.07563025842291002, f1_train: 0.09203902712513712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [08:15<00:00,  4.46s/it]\n",
      "100%|██████████| 28/28 [00:56<00:00,  2.03s/it]\n",
      "100%|██████████| 111/111 [13:53<00:00,  7.50s/it]  \n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, f1_test: 0.1428102915236478, f1_train: 0.15460786352792671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [09:15<00:00,  5.01s/it]\n",
      "100%|██████████| 28/28 [01:22<00:00,  2.94s/it]\n",
      "100%|██████████| 111/111 [04:09<00:00,  2.25s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, f1_test: 0.17246514664654855, f1_train: 0.2138671698634403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [08:41<00:00,  4.70s/it]\n",
      "100%|██████████| 28/28 [01:05<00:00,  2.35s/it]\n",
      "100%|██████████| 111/111 [04:14<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, f1_test: 0.18094917144083028, f1_train: 0.21149008362659855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [10:14<00:00,  5.54s/it]\n",
      "100%|██████████| 28/28 [01:10<00:00,  2.53s/it]\n",
      "100%|██████████| 111/111 [04:02<00:00,  2.18s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5, f1_test: 0.2082591584620916, f1_train: 0.20439043148659375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [08:54<00:00,  4.81s/it]\n",
      "100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
      "100%|██████████| 111/111 [04:55<00:00,  2.67s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, f1_test: 0.27389970931627894, f1_train: 0.3286745690364979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [09:22<00:00,  5.07s/it]\n",
      "100%|██████████| 28/28 [00:59<00:00,  2.13s/it]\n",
      "100%|██████████| 111/111 [05:11<00:00,  2.81s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7, f1_test: 0.14673339157736376, f1_train: 0.19036634050896634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [13:14<00:00,  7.16s/it]\n",
      "100%|██████████| 28/28 [01:44<00:00,  3.75s/it]\n",
      "100%|██████████| 111/111 [05:10<00:00,  2.79s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, f1_test: 0.18370243637682568, f1_train: 0.23171105066151887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [08:51<00:00,  4.79s/it]\n",
      "100%|██████████| 28/28 [00:57<00:00,  2.04s/it]\n",
      "100%|██████████| 111/111 [04:21<00:00,  2.36s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9, f1_test: 0.2502567657499155, f1_train: 0.3006708938285688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [09:54<00:00,  5.35s/it]\n",
      "100%|██████████| 28/28 [01:02<00:00,  2.25s/it]\n",
      "100%|██████████| 111/111 [04:22<00:00,  2.36s/it]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, f1_test: 0.23752302161354205, f1_train: 0.31317624776374475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 68/111 [05:36<04:07,  5.77s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b97ebd178e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwavs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#     if epoch % 10 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\environmentkaggle\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             )\n\u001b[0;32m    488\u001b[0m         torch.autograd.backward(\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         )\n\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\environmentkaggle\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    197\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m def grad(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\environmentkaggle\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mBackwardCFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FunctionBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFunctionCtx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_HookMixin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m         \u001b[1;31m# The user should define either backward or vjp but never both.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch = 10\n",
    "best_f1 = 0\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    for wavs, labs in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        #wavs, labs = wavs.cuda(), labs.cuda()\n",
    "        outputs = model(wavs)\n",
    "        loss = criterion(outputs, labs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#     if epoch % 10 == 0:\n",
    "    f1 = eval_model(model, val_loader)\n",
    "    f1_train = eval_model(model, train_loader)\n",
    "    print(f'epoch: {epoch}, f1_test: {f1}, f1_train: {f1_train}')\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), '../baseline_fulldiv.pt')\n",
    "        \n",
    "    lr = lr * 0.95\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/93 [00:00<?, ?it/s]\u001b[AC:\\Users\\rethn\\anaconda3\\envs\\environmentkaggle\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "\n",
      "  1%|          | 1/93 [00:11<16:59, 11.09s/it]\u001b[A\n",
      "  2%|▏         | 2/93 [00:17<14:32,  9.59s/it]\u001b[A\n",
      "  3%|▎         | 3/93 [00:22<12:23,  8.26s/it]\u001b[A\n",
      "  4%|▍         | 4/93 [00:34<13:55,  9.38s/it]\u001b[A\n",
      "  5%|▌         | 5/93 [00:44<14:15,  9.72s/it]\u001b[A\n",
      "  6%|▋         | 6/93 [00:54<13:50,  9.55s/it]\u001b[A\n",
      "  8%|▊         | 7/93 [00:59<11:48,  8.24s/it]\u001b[A\n",
      "  9%|▊         | 8/93 [01:03<09:59,  7.05s/it]\u001b[A\n",
      " 10%|▉         | 9/93 [01:07<08:32,  6.10s/it]\u001b[A\n",
      " 11%|█         | 10/93 [01:11<07:29,  5.41s/it]\u001b[A\n",
      " 12%|█▏        | 11/93 [01:15<06:47,  4.97s/it]\u001b[A\n",
      " 13%|█▎        | 12/93 [01:19<06:18,  4.67s/it]\u001b[A\n",
      " 14%|█▍        | 13/93 [01:22<05:35,  4.20s/it]\u001b[A\n",
      " 15%|█▌        | 14/93 [01:25<05:12,  3.95s/it]\u001b[A\n",
      " 16%|█▌        | 15/93 [01:30<05:24,  4.15s/it]\u001b[A\n",
      " 17%|█▋        | 16/93 [01:34<05:13,  4.07s/it]\u001b[A\n",
      " 18%|█▊        | 17/93 [01:37<04:50,  3.83s/it]\u001b[A\n",
      " 19%|█▉        | 18/93 [01:40<04:33,  3.65s/it]\u001b[A\n",
      " 20%|██        | 19/93 [01:43<04:24,  3.57s/it]\u001b[A\n",
      " 22%|██▏       | 20/93 [01:48<04:37,  3.80s/it]\u001b[A\n",
      " 23%|██▎       | 21/93 [01:52<04:33,  3.80s/it]\u001b[A\n",
      " 24%|██▎       | 22/93 [01:55<04:28,  3.78s/it]\u001b[A\n",
      " 25%|██▍       | 23/93 [01:59<04:21,  3.73s/it]\u001b[A\n",
      " 26%|██▌       | 24/93 [02:03<04:33,  3.96s/it]\u001b[A\n",
      " 27%|██▋       | 25/93 [02:07<04:18,  3.81s/it]\u001b[A\n",
      " 28%|██▊       | 26/93 [02:11<04:16,  3.83s/it]\u001b[A\n",
      " 29%|██▉       | 27/93 [02:14<04:01,  3.65s/it]\u001b[A\n",
      " 30%|███       | 28/93 [02:18<04:02,  3.73s/it]\u001b[A\n",
      " 31%|███       | 29/93 [02:21<03:53,  3.65s/it]\u001b[A\n",
      " 32%|███▏      | 30/93 [02:25<03:54,  3.72s/it]\u001b[A\n",
      " 33%|███▎      | 31/93 [02:31<04:28,  4.33s/it]\u001b[A\n",
      " 34%|███▍      | 32/93 [02:42<06:24,  6.31s/it]\u001b[A\n",
      " 35%|███▌      | 33/93 [02:52<07:17,  7.30s/it]\u001b[A\n",
      " 37%|███▋      | 34/93 [02:55<06:01,  6.12s/it]\u001b[A\n",
      " 38%|███▊      | 35/93 [02:58<05:01,  5.20s/it]\u001b[A\n",
      " 39%|███▊      | 36/93 [03:01<04:19,  4.56s/it]\u001b[A\n",
      " 40%|███▉      | 37/93 [03:07<04:42,  5.04s/it]\u001b[A\n",
      " 41%|████      | 38/93 [03:13<04:51,  5.31s/it]\u001b[A\n",
      " 42%|████▏     | 39/93 [03:26<06:56,  7.71s/it]\u001b[A\n",
      " 43%|████▎     | 40/93 [03:30<05:44,  6.50s/it]\u001b[A\n",
      " 44%|████▍     | 41/93 [03:33<04:41,  5.42s/it]\u001b[A\n",
      " 45%|████▌     | 42/93 [03:39<04:52,  5.73s/it]\u001b[A\n",
      " 46%|████▌     | 43/93 [03:43<04:13,  5.07s/it]\u001b[A\n",
      " 47%|████▋     | 44/93 [03:46<03:44,  4.59s/it]\u001b[A\n",
      " 48%|████▊     | 45/93 [03:51<03:39,  4.57s/it]\u001b[A\n",
      " 49%|████▉     | 46/93 [03:54<03:19,  4.24s/it]\u001b[A\n",
      " 51%|█████     | 47/93 [03:58<03:05,  4.02s/it]\u001b[A\n",
      " 52%|█████▏    | 48/93 [04:01<02:50,  3.78s/it]\u001b[A\n",
      " 53%|█████▎    | 49/93 [04:04<02:39,  3.62s/it]\u001b[A\n",
      " 54%|█████▍    | 50/93 [04:08<02:32,  3.55s/it]\u001b[A\n",
      " 55%|█████▍    | 51/93 [04:12<02:30,  3.59s/it]\u001b[A\n",
      " 56%|█████▌    | 52/93 [04:15<02:23,  3.51s/it]\u001b[A\n",
      " 57%|█████▋    | 53/93 [04:18<02:16,  3.41s/it]\u001b[A\n",
      " 58%|█████▊    | 54/93 [04:22<02:14,  3.46s/it]\u001b[A\n",
      " 59%|█████▉    | 55/93 [04:28<02:47,  4.40s/it]\u001b[A\n",
      " 60%|██████    | 56/93 [04:31<02:30,  4.05s/it]\u001b[A\n",
      " 61%|██████▏   | 57/93 [04:35<02:19,  3.89s/it]\u001b[A\n",
      " 62%|██████▏   | 58/93 [04:40<02:28,  4.23s/it]\u001b[A\n",
      " 63%|██████▎   | 59/93 [04:44<02:20,  4.14s/it]\u001b[A\n",
      " 65%|██████▍   | 60/93 [04:47<02:10,  3.95s/it]\u001b[A\n",
      " 66%|██████▌   | 61/93 [04:51<02:00,  3.76s/it]\u001b[A\n",
      " 67%|██████▋   | 62/93 [04:55<01:57,  3.78s/it]\u001b[A\n",
      " 68%|██████▊   | 63/93 [04:58<01:50,  3.69s/it]\u001b[A\n",
      " 69%|██████▉   | 64/93 [05:01<01:41,  3.50s/it]\u001b[A\n",
      " 70%|██████▉   | 65/93 [05:04<01:35,  3.41s/it]\u001b[A\n",
      " 71%|███████   | 66/93 [05:07<01:30,  3.34s/it]\u001b[A\n",
      " 72%|███████▏  | 67/93 [05:11<01:26,  3.33s/it]\u001b[A\n",
      " 73%|███████▎  | 68/93 [05:15<01:27,  3.52s/it]\u001b[A\n",
      " 74%|███████▍  | 69/93 [05:19<01:28,  3.67s/it]\u001b[A\n",
      " 75%|███████▌  | 70/93 [05:23<01:27,  3.78s/it]\u001b[A\n",
      " 76%|███████▋  | 71/93 [05:27<01:27,  3.99s/it]\u001b[A\n",
      " 77%|███████▋  | 72/93 [05:32<01:28,  4.22s/it]\u001b[A\n",
      " 78%|███████▊  | 73/93 [05:35<01:18,  3.91s/it]\u001b[A\n",
      " 80%|███████▉  | 74/93 [05:40<01:17,  4.08s/it]\u001b[A\n",
      " 81%|████████  | 75/93 [05:43<01:07,  3.74s/it]\u001b[A\n",
      " 82%|████████▏ | 76/93 [05:47<01:06,  3.90s/it]\u001b[A\n",
      " 83%|████████▎ | 77/93 [05:50<00:58,  3.66s/it]\u001b[A\n",
      " 84%|████████▍ | 78/93 [05:53<00:52,  3.47s/it]\u001b[A\n",
      " 85%|████████▍ | 79/93 [05:56<00:48,  3.45s/it]\u001b[A\n",
      " 86%|████████▌ | 80/93 [06:01<00:48,  3.70s/it]\u001b[A\n",
      " 87%|████████▋ | 81/93 [06:05<00:44,  3.73s/it]\u001b[A\n",
      " 88%|████████▊ | 82/93 [06:08<00:41,  3.80s/it]\u001b[A\n",
      " 89%|████████▉ | 83/93 [06:13<00:38,  3.87s/it]\u001b[A\n",
      " 90%|█████████ | 84/93 [06:17<00:35,  3.99s/it]\u001b[A\n",
      " 91%|█████████▏| 85/93 [06:21<00:31,  3.93s/it]\u001b[A\n",
      " 92%|█████████▏| 86/93 [06:25<00:28,  4.11s/it]\u001b[A\n",
      " 94%|█████████▎| 87/93 [06:29<00:24,  4.10s/it]\u001b[A\n",
      " 95%|█████████▍| 88/93 [06:33<00:20,  4.00s/it]\u001b[A\n",
      " 96%|█████████▌| 89/93 [06:36<00:14,  3.73s/it]\u001b[A\n",
      " 97%|█████████▋| 90/93 [06:39<00:10,  3.48s/it]\u001b[A\n",
      " 98%|█████████▊| 91/93 [06:43<00:07,  3.52s/it]\u001b[A\n",
      " 99%|█████████▉| 92/93 [06:46<00:03,  3.54s/it]\u001b[A\n",
      "100%|██████████| 93/93 [06:48<00:00,  4.39s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "# make a model\n",
    "model_name = 'baseline_fulldiv.pt'\n",
    "#model = BaseLineModel().cuda()\n",
    "model = BaseLineModel()\n",
    "model.load_state_dict(torch.load(os.path.join('..', model_name)))\n",
    "model.eval()\n",
    "forecast = []\n",
    "with torch.no_grad():\n",
    "    for wavs in tqdm(test_loader):\n",
    "        #wavs = wavs.cuda()\n",
    "        outputs = model.inference(wavs)\n",
    "        outputs = outputs.detach().cpu().numpy().argmax(axis=1)\n",
    "        forecast.append(outputs)\n",
    "forecast = [x for sublist in forecast for x in sublist]\n",
    "decoder = {classes_dict[cl]:cl for cl in classes_dict}\n",
    "forecast = pd.Series(forecast).map(decoder)\n",
    "df_test['label'] = forecast\n",
    "df_test.to_csv(f'{model_name}.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
